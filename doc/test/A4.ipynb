{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "from load_compas_data import *\n",
    "import utils as ut\n",
    "import funcs_disp_mist as fdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_classifier(x_train, y_train, x_control_train, \n",
    "                          loss_function, EPS, cons_params,\n",
    "                         x_test, y_test, x_control_test, sensitive_attrs):\n",
    "    w = fdm.train_model_disp_mist(x_train, y_train, x_control_train, \n",
    "                                  loss_function, EPS, cons_params)\n",
    "\n",
    "    train_score, test_score, cov_all_train, cov_all_test, s_attr_to_fp_fn_train, s_attr_to_fp_fn_test = fdm.get_clf_stats(w, x_train, y_train, x_control_train, \n",
    "                        x_test, y_test, x_control_test, sensitive_attrs)\n",
    "\n",
    "    return w, test_score, s_attr_to_fp_fn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file 'compas-scores-two-years.csv' in the current directory...\n",
      "File found in current directory..\n",
      "\n",
      "Number of people recidivating within two years\n",
      "-1    2795\n",
      " 1    2483\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Features we will be using for classification are: ['intercept', 'age_cat_25 - 45', 'age_cat_Greater than 45', 'age_cat_Less than 25', 'race', 'sex', 'priors_count', 'c_charge_degree'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load the data \"\"\"\n",
    "data_type = 1\n",
    "X, y, x_control = load_compas_data()\n",
    "sensitive_attrs = list(x_control.keys())\n",
    "\n",
    "\n",
    "\"\"\" Split the data into train and test \"\"\"\n",
    "train_fold_size = 0.5\n",
    "x_train, y_train, x_control_train, x_test, y_test, x_control_test = ut.split_into_train_test(X, y, x_control, train_fold_size)\n",
    "\n",
    "cons_params = None # constraint parameters, will use them later\n",
    "loss_function = \"logreg\" # perform the experiments with logistic regression\n",
    "EPS = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Unconstrained (original) classifier ==\n",
      "\n",
      "\n",
      "Accuracy: 0.671\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.35 || 0.32 ||\n",
      "||  1  || 0.15 || 0.59 ||\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Classify the data while optimizing for accuracy \"\"\"\n",
    "print()\n",
    "print(\"== Unconstrained (original) classifier ==\")\n",
    "w_uncons, acc_uncons, s_attr_to_fp_fn_test_uncons = train_test_classifier(x_train, y_train, x_control_train, \n",
    "                      loss_function, EPS, cons_params,\n",
    "                     x_test, y_test, x_control_test, sensitive_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "== DM Algo ==\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.653\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.28 || 0.41 ||\n",
      "||  1  || 0.24 || 0.51 ||\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Now classify such that we optimize for accuracy while achieving perfect fairness \"\"\"\n",
    "\n",
    "print()\n",
    "print(\"\\n\\n== DM Algo ==\")\n",
    "print(\"\\n\\n== Constraints on FPR ==\")\t# setting parameter for constraints\n",
    "cons_type = 1 # FPR constraint \n",
    "tau = 5.0\n",
    "mu = 1.2\n",
    "sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:0}, 2:{0:0, 1:0}}} \n",
    "cons_params = {\"cons_type\": cons_type, \n",
    "                \"tau\": tau, \n",
    "                \"mu\": mu, \n",
    "                \"sensitive_attrs_to_cov_thresh\": sensitive_attrs_to_cov_thresh}\n",
    "\n",
    "w_cons, acc_cons, s_attr_to_fp_fn_test_cons  = train_test_classifier(x_train, y_train, x_control_train, \n",
    "                      loss_function, EPS, cons_params,\n",
    "                     x_test, y_test, x_control_test, sensitive_attrs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.655\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.29 || 0.39 ||\n",
      "||  1  || 0.29 || 0.44 ||\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n== Constraints on FNR ==\")\t# setting parameter for constraints\n",
    "cons_type = 2 # FNR constraint \n",
    "tau = 5.0\n",
    "mu = 1.2\n",
    "sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:0}, 2:{0:0, 1:0}}} \n",
    "cons_params = {\"cons_type\": cons_type, \n",
    "                \"tau\": tau, \n",
    "                \"mu\": mu, \n",
    "                \"sensitive_attrs_to_cov_thresh\": sensitive_attrs_to_cov_thresh}\n",
    "\n",
    "w_cons_FNR, acc_cons_FNR, s_attr_to_fp_fn_test_cons_FNR  = train_test_classifier(x_train, y_train, x_control_train, \n",
    "                      loss_function, EPS, cons_params,\n",
    "                     x_test, y_test, x_control_test, sensitive_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "== DM-sen Algo ==\n",
      "\n",
      "\n",
      "== Constraints on  both FPR and FNR==\n",
      "\n",
      "\n",
      "Accuracy: 0.657\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.29 || 0.39 ||\n",
      "||  1  || 0.25 || 0.48 ||\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n== DM-sen Algo ==\")\n",
    "print(\"\\n\\n== Constraints on  both FPR and FNR==\")\t# setting parameter for constraints\n",
    "cons_type = 4 # both FPR and FNR constraint \n",
    "tau = 5.0\n",
    "mu = 1.2\n",
    "sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:0}, 2:{0:0, 1:0}}} \n",
    "cons_params = {\"cons_type\": cons_type, \n",
    "                \"tau\": tau, \n",
    "                \"mu\": mu, \n",
    "                \"sensitive_attrs_to_cov_thresh\": sensitive_attrs_to_cov_thresh}\n",
    "\n",
    "w_cons_both, acc_cons_both, s_attr_to_fp_fn_test_cons_both  = train_test_classifier(x_train, y_train, x_control_train, \n",
    "                  loss_function, EPS, cons_params,\n",
    "                 x_test, y_test, x_control_test, sensitive_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
